{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TensorFlow基本操作\n",
    "```\n",
    "Author: PeterSansan\n",
    "Project: https://github.com/PeterSansan/TF_ACTION\n",
    "Time : 2017.04.25\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [目录]\n",
    "- [1、算法运算比较GPU与CPU的性能](#1) \n",
    "- [2、另一种会话形式](#2)\n",
    "- [3、assign赋值函数](#3)\n",
    "- [4、fetch取数据 ](#4)\n",
    "- [5、feed填数据](#5) \n",
    "- [6、get_variable与Variable的一点区别](#6)\n",
    "- [7、argmax](#7)\n",
    "- [8、dropout](#8)\n",
    "- [9、保存数据](#9)\n",
    "- [10、读取数据](#10)\n",
    "- [11、变量的赋值不要用run](#11)\n",
    "- [12、print输出到文件](#12)\n",
    "- [13、初始化函数](#13)\n",
    "- [14、命名域与共享变量](#14)\n",
    "- [15、查看CPU与GPU使用情况](#15)\n",
    "- [16. tf.reshape](#16)\n",
    "- [17.tf.transpose](#17)\n",
    "- [18.tf.gather](#18)\n",
    "- [19.加减乘除](#19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"1\">1.乘法运算比较GPU与CPU的性能</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spend time 0.529668 s\n"
     ]
    }
   ],
   "source": [
    "begin=time.time() # 时间开始\n",
    "with tf.Session() as sess0:\n",
    "    with tf.device(\"/gpu:0\"):#g 不加这个话就不能控制用CPU还是GPU，默认是GPU\n",
    "        matrix1 = np.random.rand(1000,1500).astype(np.float32)\n",
    "        matrix2 = np.random.rand(1500,1000).astype(np.float32)\n",
    "        product = tf.matmul(matrix1, matrix2)\n",
    "        result = sess0.run(product)\n",
    "\n",
    "end = time.time()  # 时间结束\n",
    "print(\"Spend time %f s\" %(end - begin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spend time 0.112948 s\n"
     ]
    }
   ],
   "source": [
    "begin=time.time() # 时间开始\n",
    "with tf.Session() as sess0:\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        matrix1 = np.random.rand(1000,1500).astype(np.float32)\n",
    "        matrix2 = np.random.rand(1500,1000).astype(np.float32)\n",
    "        product = tf.matmul(matrix1, matrix2)\n",
    "        result = sess0.run(product)\n",
    "\n",
    "end = time.time()  # 时间结束\n",
    "print(\"Spend time %f s\" %(end - begin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面跑出来的结果可以看出GPU比CPU要快一些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"2\">2.另一种会话形式</span>\n",
    "前面那种会话是在模型与数据准备好的情况下，开启会话的，一般用`with tf.Session() as sess:`包含在里面，其实还有另外一种交互式更多好的会话形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 34.99643707  32.52858734  36.30847549 ...,  34.48641968  35.22559357\n",
      "   34.24759674]\n",
      " [ 37.91554642  37.74853897  38.73323441 ...,  38.33403397  38.23762131\n",
      "   38.75738525]\n",
      " [ 38.47691345  37.55822754  39.24243164 ...,  37.76333237  41.1979332\n",
      "   40.01792145]\n",
      " ..., \n",
      " [ 37.85952377  36.12457275  38.36671066 ...,  37.33881378  41.97075272\n",
      "   36.95290756]\n",
      " [ 37.72820282  38.76245499  39.18152618 ...,  37.00209045  37.89226913\n",
      "   37.62464523]\n",
      " [ 35.72961044  35.91385651  39.07429886 ...,  36.83859634  36.05078888\n",
      "   36.57166672]]\n"
     ]
    }
   ],
   "source": [
    "#deploy a session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#design the grape\n",
    "matrix1 = np.random.rand(200,150).astype(np.float32)\n",
    "matrix2 = np.random.rand(150,200).astype(np.float32)\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "#run the operation\n",
    "print(product.eval())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span id=\"3\">3.assign赋值函数</span>\n",
    "实现了计算器功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#design the graph\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)  #赋值\n",
    "\n",
    "#initialization\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "#run \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(state))\n",
    "    for _ in range(4):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"4\">4.fetch取数据</span>\n",
    "这种方法实际上我们上面一直在用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.0, 7.0]\n",
      "[7.0]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)    # 定义三个常量\n",
    "\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([mul, intermed])\n",
    "    print(result)  # 取两个结果\n",
    "    result = sess.run([intermed])\n",
    "    print(result)   # 取一个结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"5\">5.feed填数据</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3.,  3.,  3.],\n",
      "       [ 3.,  3.,  3.],\n",
      "       [ 3.,  3.,  3.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.placeholder(tf.float32,shape=(3, 3))\n",
    "input2 = tf.placeholder(tf.float32,shape=(3, 3))\n",
    "output = tf.matmul(input1, input2)#matmul is different mul\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    rand_array = np.ones([3, 3])\n",
    "    print(sess.run([output], feed_dict={input1: rand_array,input2: rand_array}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"6\">6.get_variable与Variable的一点区别</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'counter:0' shape=() dtype=int32_ref>, <tf.Variable 'a:0' shape=(5, 2) dtype=float32_ref>, <tf.Variable 'd:0' shape=(3, 3) dtype=float32_ref>]\n",
      "[u'counter:0', u'a:0', u'd:0']\n",
      "[0,\n",
      " array([[ 0.41369224,  0.74239981],\n",
      "       [ 0.61096227, -0.31156224],\n",
      "       [-0.21275789, -0.21643883],\n",
      "       [ 0.56238353,  0.10704696],\n",
      "       [ 0.29308939,  0.57434237]], dtype=float32),\n",
      " array([[ 0.24032283,  0.21842706,  0.2987926 ],\n",
      "       [ 0.13671792,  0.97999871,  0.31238902],\n",
      "       [ 0.30105329,  0.16962588,  0.60516846]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "\n",
    "a = tf.get_variable('a',shape=[5,2])    # 默认 trainable=True\n",
    "b = tf.get_variable('b',shape=[2,5],trainable=False)\n",
    "c = tf.constant([1,2,3],dtype=tf.int32,shape=[8],name='c') # 因为是常量，所以trainable=False\n",
    "d = tf.Variable(tf.random_uniform(shape=[3,3]),name='d')\n",
    "\n",
    "tvar = tf.trainable_variables()\n",
    "tvar_name = [x.name for x in tvar]\n",
    "print(tvar)\n",
    "# [<tensorflow.python.ops.variables.Variable object at 0x7f9c8db8ca20>, <tensorflow.python.ops.variables.Variable object at 0x7f9c8db8c9b0>]\n",
    "print(tvar_name)\n",
    "# ['a:0', 'd:0']\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pprint(sess.run(tvar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"7\">7.argmax</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10336685  0.12803698  0.21542645  0.19146633]\n",
      " [ 0.24188113 -0.0112586   0.53921056  0.96471953]\n",
      " [ 0.68974805  0.44744492  0.1435833   0.26476955]]\n",
      "[2 2 1 1]\n",
      "[2 3 0]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "aa = tf.get_variable(name = 'aa',\n",
    "                    shape=[3,4],\n",
    "                    dtype = tf.float32,\n",
    "                    initializer=tf.random_uniform_initializer(minval=-1,maxval=1))\n",
    "\n",
    "bb = tf.argmax(input = aa,dimension = 0) # 选出每列中最大值的位置\n",
    "cc = tf.argmax(input = aa,dimension = 1) # 选出每行中最大值的位置\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(aa))\n",
    "print(sess.run(bb))\n",
    "print(sess.run(cc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span id=\"8\">8、dropout</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01069868 -0.41452724  0.47348642 -0.52076149  0.89870882]\n",
      " [ 0.72514248  0.08796155  0.31262529  0.01385671 -0.07708627]]\n",
      "[[ 0.01337335 -0.51815903  0.59185803 -0.65095186  0.        ]\n",
      " [ 0.9064281   0.10995194  0.39078161  0.01732089 -0.09635784]]\n",
      "[[ 0.01069868 -0.41452724  0.47348642 -0.52076149  0.89870882]\n",
      " [ 0.72514248  0.08796155  0.31262529  0.01385671 -0.07708627]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "ai = tf.get_variable('ai',shape=[2,5])\n",
    "bi = ai\n",
    "ci = ai\n",
    "a_drop = tf.nn.dropout(ai,0.8)\n",
    "c_drop = tf.nn.dropout(ci,1)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(sess.run(ai))\n",
    "print(sess.run(a_drop))\n",
    "print(sess.run(c_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"9\">9、保存数据</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Parent directory of ./../codes/my_save_net/save_net.ckpt doesn't exist, can't save.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c9cfdf01b02f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./../codes/my_save_net/save_net.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"save to path:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"weights:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1380\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsDirectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m       raise ValueError(\n\u001b[0;32m-> 1382\u001b[0;31m           \"Parent directory of {} doesn't exist, can't save.\".format(save_path))\n\u001b[0m\u001b[1;32m   1383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parent directory of ./../codes/my_save_net/save_net.ckpt doesn't exist, can't save."
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# save to file  \n",
    "# 下面代码注释掉，因为一个文件保存与读取不要重复了\n",
    "W = tf.Variable([[1,2,3],[4,5,6]],dtype = tf.float32,name='weight')  \n",
    "b = tf.Variable([[1,2,3]],dtype = tf.float32,name='biases')  \n",
    "  \n",
    "init = tf.global_variables_initializer()  \n",
    "saver = tf.train.Saver()  \n",
    "with tf.Session() as sess:  \n",
    "    sess.run(init)  \n",
    "    save_path = saver.save(sess,\"./save_par/save_par.ckpt\")  \n",
    "    print (\"save to path:\",save_path)  \n",
    "    print (\"weights:\",sess.run(W))  \n",
    "    print (\"biases:\",sess.run(b)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"10\">10、加载数据</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "#W = tf.Variable(np.arange(6).reshape((2,3)),dtype = tf.float32,name='weight')  \n",
    "#b = tf.Variable(np.arange(3).reshape((1,3)),dtype = tf.float32,name='biases')  \n",
    "  \n",
    "#saver = tf.train.Saver()  \n",
    "#with tf.Session() as sess:  \n",
    "#        saver.restore(sess,\"./save_par/save_par.ckpt\")  \n",
    "#        print (\"weights:\",sess.run(W))  \n",
    "#        print (\"biases:\",sess.run(b))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"11\">11、变量的赋值不要用run</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "t1 = time.time()  \n",
    "x = tf.Variable([1.0])  \n",
    "b =1.0  \n",
    "start1 = time.time()  \n",
    "with tf.Session() as sess:  \n",
    "    sess.run(tf.global_variables_initializer())  \n",
    "    #通过sess.run的方式读变量  \n",
    "    for step in range(5000):  \n",
    "        res = sess.run(x)  \n",
    "    print(\"通过sess.run的方式读变量所需的时间:\",time.time()-start1)  \n",
    "    start2 = time.time()  \n",
    "    for step in range(5000):  \n",
    "        a = b  \n",
    "    print(\"通过直接赋值的手段读变量所需的时间:\",time.time()-start2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"12\">12、print输出到文件</span>\n",
    "这个功能不是TensorFlow的，放在这里只是它也很常用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=open('a.txt','a+') # 追加\n",
    "\n",
    "old=sys.stdout #将当前系统输出储存到一个临时变量中\n",
    "sys.stdout=f  #输出重定向到文件\n",
    "print('Hello weird') #测试一个打印输出\n",
    "sys.stdout.flush() # 刷新文件流\n",
    "sys.stdout=old #还原原系统输出\n",
    "f.close() \n",
    "print(open('a.txt','r').read())\n",
    "\n",
    "# 第二种方法\n",
    "# f=open('test.txt','a+')\n",
    "# s= '123'\n",
    "# abc= '456'\n",
    "# print >> f, s,abc\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"13\">13、使用初始化函数</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "value = [0,1,2,3,4,5,6,7]\n",
    "#value = np.array(value)  # 注释掉没有影响\n",
    "#value = value.reshape([2,4])\n",
    "init = tf.constant_initializer(value)\n",
    "print('fitting shape:')\n",
    "tf.reset_default_graph()\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[2,4],initializer=init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('larger shape:')  #小型的初始化是不允许的，也就是说shape小于原来的大小\n",
    "tf.reset_default_graph()\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[3,4],initializer = init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('random_normal_initializer:')\n",
    "tf.reset_default_graph()\n",
    "init = tf.random_normal_initializer(mean=0.0,stddev=1.0) #正态分布函数\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[3,4],initializer = init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('truncated_normal_initializer:')\n",
    "tf.reset_default_graph()\n",
    "init = tf.truncated_normal_initializer(mean=0.0,stddev=1.0)\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[3,4],initializer = init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('random_uniform_initializer:')\n",
    "tf.reset_default_graph()\n",
    "init = tf.random_uniform_initializer(minval=0,maxval=None) #均匀分布随机数\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[3,4],initializer = init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "【说明】：\n",
    "tf.random_normal | tf.truncated_normal | tf.random_uniform\n",
    "tf.random_normal(shape,mean=0.0,stddev=1.0,dtype=tf.float32,seed=None,name=None)\n",
    "tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "tf.random_uniform(shape,minval=0,maxval=None,dtype=tf.float32,seed=None,name=None)\n",
    "这几个都是用于生成随机数tensor的。尺寸是shape\n",
    "random_normal: 正太分布随机数，均值mean,标准差stddev\n",
    "truncated_normal:截断正态分布随机数，均值mean,标准差stddev,不过只保留[mean-2*stddev,mean+2*stddev]范围内的随机数\n",
    "random_uniform:均匀分布随机数，范围为[minval,maxval]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"14\">14、命名域与共享变量</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "# 不同的命名域与变量\n",
    "with tf.variable_scope(\"foo\"):\n",
    "  with tf.variable_scope(\"bar\"):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    print(v.name)\n",
    "\n",
    "print(v.name)\n",
    "\n",
    "with tf.variable_scope(\"foo1\"):\n",
    "  with tf.variable_scope(\"bar1\"):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    print(v.name)\n",
    "print(v.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 变量共享（相同变量）\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "with tf.variable_scope(\"xxx\"):\n",
    "  a = tf.get_variable(\"a\",[1])\n",
    "with tf.variable_scope(\"xxx\",reuse=True):   # 采用xxx/a的值\n",
    "  a1 = tf.get_variable(\"a\",[1])\n",
    "print(a,a1)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(a.eval(),a1.eval()) #如果初始化为None,则会采用variable_scope的初始化值，\n",
    "# 如果也是None,则采用uniform_unit_scaling_initializer\n",
    "assert a==a1  # a , a1 是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 变量共享（相同变量）另一种写法\n",
    "tf.reset_default_graph()\n",
    "with tf.variable_scope(\"yyy\") as scope:\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    scope.reuse_variables()\n",
    "    v1 = tf.get_variable(\"v\", [1])\n",
    "assert v1 == v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 为防止在没有使用reuse的情况下出现相现的共享变量，则会弹出异常,如下面是有错误的\n",
    "# with tf.variable_scope(\"zzz\"):\n",
    "  # v = tf.get_variable(\"v\",[1])\n",
    "  # v1 = tf.get_variable(\"v\",[1])\n",
    "  # Raises ValueError(\"...v already exists ...\").\n",
    "  \n",
    "# 为防止在使用reuse的情况下引用了之前没有的共享变量，则会弹出异常，如下面是有错误的\n",
    "# with tf.variable_scope(\"aaa\",reuse=True):\n",
    "  # v = tf.get_variable(\"v\",[1])\n",
    "  # Raises ValueError(\"... v does not exists...\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"15\">15.查看CPU与GPU使用</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CPU:\n",
    "    sensors   or   watch sensors\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "GPU:\n",
    "    nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader\n",
    "    or \n",
    "    nvidia-smi -a  # 可以看到显示的所有信息，包括什么温度会关自动关闭\n",
    "    or\n",
    "    watch -n 1 nvidia-smi  # 1秒的频率\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"16\">16.tf.reshape</span>\n",
    "```\n",
    "tf.reshape(tensor,shape,name=None)\n",
    "\n",
    "顾名思义，就是将tensor按照新的shape重新排列。一般来说，shape有三种用法： \n",
    "如果 shape=[-1], 表示要将tensor展开成一个list \n",
    "如果 shape=[a,b,c,…] 其中每个a,b,c,..均>0，那么就是常规用法 \n",
    "如果 shape=[a,-1,c,…] 此时b=-1，a,c,..依然>0。这表示tf会根据tensor的原尺寸，自动计算b的值。 \n",
    "官方给的例子已经很详细了，我就不写示例代码了\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# 官方例子\n",
    "# tensor 't' is [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "# tensor 't' has shape [9]\n",
    "reshape(t, [3, 3]) ==> [[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]]\n",
    "\n",
    "# tensor 't' is [[[1, 1], [2, 2]],\n",
    "#                [[3, 3], [4, 4]]]\n",
    "# tensor 't' has shape [2, 2, 2]\n",
    "reshape(t, [2, 4]) ==> [[1, 1, 2, 2],\n",
    "                        [3, 3, 4, 4]]\n",
    "\n",
    "# tensor 't' is [[[1, 1, 1],\n",
    "#                 [2, 2, 2]],\n",
    "#                [[3, 3, 3],\n",
    "#                 [4, 4, 4]],\n",
    "#                [[5, 5, 5],\n",
    "#                 [6, 6, 6]]]\n",
    "# tensor 't' has shape [3, 2, 3]\n",
    "# pass '[-1]' to flatten 't'\n",
    "reshape(t, [-1]) ==> [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]\n",
    "\n",
    "# -1 can also be used to infer the shape\n",
    "# -1 is inferred to be 9:\n",
    "reshape(t, [2, -1]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]\n",
    "\n",
    "# -1 is inferred to be 2:\n",
    "reshape(t, [-1, 9]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]\n",
    "\n",
    "# -1 is inferred to be 3:\n",
    "reshape(t, [ 2, -1, 3]) ==> [[[1, 1, 1],\n",
    "                              [2, 2, 2],\n",
    "                              [3, 3, 3]],\n",
    "                             [[4, 4, 4],\n",
    "                              [5, 5, 5],\n",
    "                              [6, 6, 6]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"17\">17.tf.transpose</span>\n",
    "转置函数：\n",
    "\n",
    "转见：[csdn](http://blog.csdn.net/u010417185/article/details/51900441)\n",
    "\n",
    "### <span id = \"18\">18.tf.gather</span>\n",
    "筛选函数：\n",
    "\n",
    "转见：[csdn](http://blog.csdn.net/guotong1988/article/details/53172882)\n",
    "\n",
    "### <span id = \"19\">19.加减乘除</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.constant(5.5)\n",
    "b = tf.constant(6.5)\n",
    "sess = tf.InteractiveSession()\n",
    "print(\"Subtracting a from b:\",sess.run(tf.subtract(b, a)))\n",
    "print(\"Adding a and b:\",sess.run(tf.add(a, b)))\n",
    "print(\"Multiplying a and b:\",sess.run(tf.multiply(a, b)))\n",
    "print(\"Dividing a and b:\",sess.run(tf.divide(b, a)))\n",
    "print(\"Floor dividing a and b:\",sess.run(tf.floor_div(b, a)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
