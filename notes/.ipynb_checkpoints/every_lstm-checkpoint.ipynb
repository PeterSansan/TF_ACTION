{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 所有人都能学会用Python写出RNN代码\n",
    "英文原文：[Anyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN)](http://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/)\n",
    "\n",
    "中文原文：[所有人都能学会用Python写出RNN-LSTM代码](http://magicly.me/2017/03/09/iamtrask-anyone-can-code-lstm/?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io)\n",
    "\n",
    "说明：这代码是RNN代码，并不是LSTM的代码\n",
    "Time: 2017-4-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy, numpy as np\n",
    "np.random.seed(0) #固定随机数生成器的种子，便于得到固定的输出，【译者注：完全是为了方便调试用的]\n",
    "# compute sigmoid nonlinearity\n",
    "def sigmoid(x): #激活函数\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# convert output of sigmoid function to its derivative\n",
    "def sigmoid_output_to_derivative(output):#激活函数的导数\n",
    "    return output*(1-output)\n",
    "\n",
    "# training dataset generation\n",
    "# 生成数据，0~255;\n",
    "int2binary = {} #整数到其二进制表示的映射\n",
    "binary_dim = 8 #暂时制作256以内的加法，可以调大\n",
    "## 以下5行代码计算0-256的二进制表示\n",
    "largest_number = pow(2,binary_dim) # 256\n",
    "binary = np.unpackbits(       # 十进制转二进制\n",
    "    np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]\n",
    "    # print int2binary[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input variables\n",
    "# 参数初始化\n",
    "alpha = 0.1 #学习速率\n",
    "input_dim = 2 #因为我们是做两个数相加，每次会喂给神经网络两个bit，所以输入的维度是2\n",
    "hidden_dim = 16 #隐藏层的神经元节点数，远比理论值要大（译者注：理论上而言，应该一个节点就可以记住有无进位了，但我试了发现4的时候都没法收敛），你可以自己调整这个数，看看调大了是容易更快地收敛还是更慢\n",
    "output_dim = 1 #我们的输出是一个数，所以维度为1\n",
    "\n",
    "# initialize neural network weights，关键参数，待更新\n",
    "synapse_0 = 2*np.random.random((input_dim,hidden_dim)) - 1 #输入层到隐藏层的转化矩阵，维度为2*16， 2是输入维度，16是隐藏层维度\n",
    "synapse_1 = 2*np.random.random((hidden_dim,output_dim)) - 1 #隐藏层到输出层的转化矩阵，维度为16*1, 1是输出维度，16是隐藏层维度\n",
    "synapse_h = 2*np.random.random((hidden_dim,hidden_dim)) - 1 #输入层到隐藏层的转化矩阵，维度为16*16，16是隐藏层维度\n",
    "\n",
    "# 译者注：np.random.random产生的是[0,1)的随机数，2 * [0, 1) - 1 => [-1, 1)，\n",
    "# 是为了有正有负更快地收敛，这涉及到如何初始化参数的问题，通常来说都是靠“经验”或者说“启发式规则”，说得直白一点就是“蒙的”！机器学习里面，超参数的选择，大部分都是这种情况，哈哈。。。\n",
    "# 我自己试了一下用【0, 2)之间的随机数，貌似不能收敛，用[0,1)就可以，呵呵。。。\n",
    "# 以下三个分别对应三个矩阵的变化，即delta W\n",
    "synapse_0_update = np.zeros_like(synapse_0)\n",
    "synapse_1_update = np.zeros_like(synapse_1)\n",
    "synapse_h_update = np.zeros_like(synapse_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:[ 3.45638663]\n",
      "Pred:[0 0 0 0 0 0 0 1]\n",
      "True:[0 1 0 0 0 1 0 1]\n",
      "9 + 60 = 1\n",
      "------------\n",
      "Error:[ 3.63389116]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 0 1 1 1 1 1 1]\n",
      "28 + 35 = 255\n",
      "------------\n",
      "Error:[ 3.91366595]\n",
      "Pred:[0 1 0 0 1 0 0 0]\n",
      "True:[1 0 1 0 0 0 0 0]\n",
      "116 + 44 = 72\n",
      "------------\n",
      "Error:[ 3.72191702]\n",
      "Pred:[1 1 0 1 1 1 1 1]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "4 + 73 = 223\n",
      "------------\n",
      "Error:[ 3.5852713]\n",
      "Pred:[0 0 0 0 1 0 0 0]\n",
      "True:[0 1 0 1 0 0 1 0]\n",
      "71 + 11 = 8\n",
      "------------\n",
      "Error:[ 2.53352328]\n",
      "Pred:[1 0 1 0 0 0 1 0]\n",
      "True:[1 1 0 0 0 0 1 0]\n",
      "81 + 113 = 162\n",
      "------------\n",
      "Error:[ 0.57691441]\n",
      "Pred:[0 1 0 1 0 0 0 1]\n",
      "True:[0 1 0 1 0 0 0 1]\n",
      "81 + 0 = 81\n",
      "------------\n",
      "Error:[ 1.42589952]\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "4 + 125 = 129\n",
      "------------\n",
      "Error:[ 0.47477457]\n",
      "Pred:[0 0 1 1 1 0 0 0]\n",
      "True:[0 0 1 1 1 0 0 0]\n",
      "39 + 17 = 56\n",
      "------------\n",
      "Error:[ 0.21595037]\n",
      "Pred:[0 0 0 0 1 1 1 0]\n",
      "True:[0 0 0 0 1 1 1 0]\n",
      "11 + 3 = 14\n",
      "------------\n",
      "Error:[ 0.3231264]\n",
      "Pred:[0 1 0 1 1 1 1 1]\n",
      "True:[0 1 0 1 1 1 1 1]\n",
      "18 + 77 = 95\n",
      "------------\n",
      "Error:[ 0.31291546]\n",
      "Pred:[0 0 1 0 0 1 1 1]\n",
      "True:[0 0 1 0 0 1 1 1]\n",
      "14 + 25 = 39\n",
      "------------\n",
      "Error:[ 0.41985062]\n",
      "Pred:[1 0 0 0 0 0 1 0]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "83 + 47 = 130\n",
      "------------\n",
      "Error:[ 0.33870993]\n",
      "Pred:[0 1 1 1 0 1 1 1]\n",
      "True:[0 1 1 1 0 1 1 1]\n",
      "73 + 46 = 119\n",
      "------------\n",
      "Error:[ 0.2248094]\n",
      "Pred:[1 0 0 0 1 1 0 1]\n",
      "True:[1 0 0 0 1 1 0 1]\n",
      "41 + 100 = 141\n",
      "------------\n",
      "Error:[ 0.23466106]\n",
      "Pred:[0 1 1 0 1 0 0 1]\n",
      "True:[0 1 1 0 1 0 0 1]\n",
      "35 + 70 = 105\n",
      "------------\n",
      "Error:[ 0.29697817]\n",
      "Pred:[1 0 0 0 0 0 1 0]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "21 + 109 = 130\n",
      "------------\n",
      "Error:[ 0.28425318]\n",
      "Pred:[1 0 0 1 0 0 0 0]\n",
      "True:[1 0 0 1 0 0 0 0]\n",
      "70 + 74 = 144\n",
      "------------\n",
      "Error:[ 0.19182073]\n",
      "Pred:[0 1 1 0 0 1 1 0]\n",
      "True:[0 1 1 0 0 1 1 0]\n",
      "59 + 43 = 102\n",
      "------------\n",
      "Error:[ 0.25523641]\n",
      "Pred:[1 0 0 1 1 0 0 1]\n",
      "True:[1 0 0 1 1 0 0 1]\n",
      "110 + 43 = 153\n",
      "------------\n",
      "Error:[ 0.27153112]\n",
      "Pred:[1 0 0 1 1 0 1 1]\n",
      "True:[1 0 0 1 1 0 1 1]\n",
      "39 + 116 = 155\n",
      "------------\n",
      "Error:[ 0.12559477]\n",
      "Pred:[0 1 1 1 0 1 1 0]\n",
      "True:[0 1 1 1 0 1 1 0]\n",
      "34 + 84 = 118\n",
      "------------\n",
      "Error:[ 0.20806802]\n",
      "Pred:[1 0 1 1 0 1 1 0]\n",
      "True:[1 0 1 1 0 1 1 0]\n",
      "123 + 59 = 182\n",
      "------------\n",
      "Error:[ 0.1765721]\n",
      "Pred:[0 1 1 1 1 0 0 1]\n",
      "True:[0 1 1 1 1 0 0 1]\n",
      "42 + 79 = 121\n",
      "------------\n",
      "Error:[ 0.17945063]\n",
      "Pred:[1 0 1 0 0 1 1 0]\n",
      "True:[1 0 1 0 0 1 1 0]\n",
      "43 + 123 = 166\n",
      "------------\n",
      "Error:[ 0.18826067]\n",
      "Pred:[0 1 0 0 0 1 0 1]\n",
      "True:[0 1 0 0 0 1 0 1]\n",
      "18 + 51 = 69\n",
      "------------\n",
      "Error:[ 0.1644686]\n",
      "Pred:[0 1 0 0 1 0 0 1]\n",
      "True:[0 1 0 0 1 0 0 1]\n",
      "37 + 36 = 73\n",
      "------------\n",
      "Error:[ 0.23233687]\n",
      "Pred:[1 1 0 0 1 0 0 0]\n",
      "True:[1 1 0 0 1 0 0 0]\n",
      "90 + 110 = 200\n",
      "------------\n",
      "Error:[ 0.1769695]\n",
      "Pred:[1 0 1 0 1 1 0 1]\n",
      "True:[1 0 1 0 1 1 0 1]\n",
      "74 + 99 = 173\n",
      "------------\n",
      "Error:[ 0.14772125]\n",
      "Pred:[0 1 1 1 0 0 0 0]\n",
      "True:[0 1 1 1 0 0 0 0]\n",
      "69 + 43 = 112\n",
      "------------\n",
      "Error:[ 0.1603061]\n",
      "Pred:[1 0 1 0 1 0 1 0]\n",
      "True:[1 0 1 0 1 0 1 0]\n",
      "95 + 75 = 170\n",
      "------------\n",
      "Error:[ 0.16059518]\n",
      "Pred:[1 0 1 0 0 1 1 0]\n",
      "True:[1 0 1 0 0 1 1 0]\n",
      "116 + 50 = 166\n",
      "------------\n",
      "Error:[ 0.12814329]\n",
      "Pred:[0 1 0 1 0 0 1 1]\n",
      "True:[0 1 0 1 0 0 1 1]\n",
      "74 + 9 = 83\n",
      "------------\n",
      "Error:[ 0.12257151]\n",
      "Pred:[0 1 1 0 0 1 1 1]\n",
      "True:[0 1 1 0 0 1 1 1]\n",
      "49 + 54 = 103\n",
      "------------\n",
      "Error:[ 0.07832366]\n",
      "Pred:[0 1 1 0 1 1 0 1]\n",
      "True:[0 1 1 0 1 1 0 1]\n",
      "104 + 5 = 109\n",
      "------------\n",
      "Error:[ 0.15381108]\n",
      "Pred:[1 0 1 0 1 1 1 1]\n",
      "True:[1 0 1 0 1 1 1 1]\n",
      "93 + 82 = 175\n",
      "------------\n",
      "Error:[ 0.12746046]\n",
      "Pred:[0 0 1 1 0 0 0 1]\n",
      "True:[0 0 1 1 0 0 0 1]\n",
      "12 + 37 = 49\n",
      "------------\n",
      "Error:[ 0.10136869]\n",
      "Pred:[0 1 0 0 0 1 0 1]\n",
      "True:[0 1 0 0 0 1 0 1]\n",
      "16 + 53 = 69\n",
      "------------\n",
      "Error:[ 0.13850405]\n",
      "Pred:[0 1 1 1 1 0 0 1]\n",
      "True:[0 1 1 1 1 0 0 1]\n",
      "70 + 51 = 121\n",
      "------------\n",
      "Error:[ 0.0819981]\n",
      "Pred:[0 1 0 1 1 0 1 0]\n",
      "True:[0 1 0 1 1 0 1 0]\n",
      "7 + 83 = 90\n",
      "------------\n",
      "Error:[ 0.10004929]\n",
      "Pred:[0 1 0 1 0 0 0 0]\n",
      "True:[0 1 0 1 0 0 0 0]\n",
      "67 + 13 = 80\n",
      "------------\n",
      "Error:[ 0.05452805]\n",
      "Pred:[0 1 1 1 0 1 1 0]\n",
      "True:[0 1 1 1 0 1 1 0]\n",
      "1 + 117 = 118\n",
      "------------\n",
      "Error:[ 0.06797]\n",
      "Pred:[0 0 1 0 1 1 0 0]\n",
      "True:[0 0 1 0 1 1 0 0]\n",
      "43 + 1 = 44\n",
      "------------\n",
      "Error:[ 0.09436406]\n",
      "Pred:[0 1 1 1 1 1 0 0]\n",
      "True:[0 1 1 1 1 1 0 0]\n",
      "37 + 87 = 124\n",
      "------------\n",
      "Error:[ 0.08322266]\n",
      "Pred:[0 1 1 0 1 0 0 0]\n",
      "True:[0 1 1 0 1 0 0 0]\n",
      "39 + 65 = 104\n",
      "------------\n",
      "Error:[ 0.10016467]\n",
      "Pred:[0 1 0 1 1 0 1 1]\n",
      "True:[0 1 0 1 1 0 1 1]\n",
      "15 + 76 = 91\n",
      "------------\n",
      "Error:[ 0.09614181]\n",
      "Pred:[0 0 1 1 0 0 0 0]\n",
      "True:[0 0 1 1 0 0 0 0]\n",
      "28 + 20 = 48\n",
      "------------\n",
      "Error:[ 0.12333791]\n",
      "Pred:[1 0 1 1 0 0 0 0]\n",
      "True:[1 0 1 1 0 0 0 0]\n",
      "92 + 84 = 176\n",
      "------------\n",
      "Error:[ 0.12358932]\n",
      "Pred:[1 1 0 1 1 1 1 1]\n",
      "True:[1 1 0 1 1 1 1 1]\n",
      "116 + 107 = 223\n",
      "------------\n",
      "Error:[ 0.05967078]\n",
      "Pred:[0 1 0 0 1 1 0 0]\n",
      "True:[0 1 0 0 1 1 0 0]\n",
      "1 + 75 = 76\n",
      "------------\n",
      "Error:[ 0.11245508]\n",
      "Pred:[1 0 1 1 0 1 0 1]\n",
      "True:[1 0 1 1 0 1 0 1]\n",
      "99 + 82 = 181\n",
      "------------\n",
      "Error:[ 0.12735116]\n",
      "Pred:[1 0 0 0 1 1 1 0]\n",
      "True:[1 0 0 0 1 1 1 0]\n",
      "26 + 116 = 142\n",
      "------------\n",
      "Error:[ 0.09245217]\n",
      "Pred:[0 1 0 0 0 1 1 1]\n",
      "True:[0 1 0 0 0 1 1 1]\n",
      "35 + 36 = 71\n",
      "------------\n",
      "Error:[ 0.08031943]\n",
      "Pred:[0 1 0 1 0 0 1 1]\n",
      "True:[0 1 0 1 0 0 1 1]\n",
      "32 + 51 = 83\n",
      "------------\n",
      "Error:[ 0.10065782]\n",
      "Pred:[0 0 1 1 1 0 1 1]\n",
      "True:[0 0 1 1 1 0 1 1]\n",
      "53 + 6 = 59\n",
      "------------\n",
      "Error:[ 0.09135723]\n",
      "Pred:[0 1 1 1 0 0 0 0]\n",
      "True:[0 1 1 1 0 0 0 0]\n",
      "100 + 12 = 112\n",
      "------------\n",
      "Error:[ 0.10468076]\n",
      "Pred:[0 1 0 1 0 0 0 1]\n",
      "True:[0 1 0 1 0 0 0 1]\n",
      "37 + 44 = 81\n",
      "------------\n",
      "Error:[ 0.07674802]\n",
      "Pred:[0 0 1 0 1 0 1 1]\n",
      "True:[0 0 1 0 1 0 1 1]\n",
      "17 + 26 = 43\n",
      "------------\n",
      "Error:[ 0.07191059]\n",
      "Pred:[1 0 0 0 1 0 1 1]\n",
      "True:[1 0 0 0 1 0 1 1]\n",
      "65 + 74 = 139\n",
      "------------\n",
      "Error:[ 0.07104761]\n",
      "Pred:[0 0 0 1 1 1 1 1]\n",
      "True:[0 0 0 1 1 1 1 1]\n",
      "12 + 19 = 31\n",
      "------------\n",
      "Error:[ 0.11951541]\n",
      "Pred:[1 0 0 1 0 0 1 1]\n",
      "True:[1 0 0 1 0 0 1 1]\n",
      "46 + 101 = 147\n",
      "------------\n",
      "Error:[ 0.1076972]\n",
      "Pred:[1 1 0 0 0 0 1 1]\n",
      "True:[1 1 0 0 0 0 1 1]\n",
      "108 + 87 = 195\n",
      "------------\n",
      "Error:[ 0.06051386]\n",
      "Pred:[0 1 1 0 0 1 1 1]\n",
      "True:[0 1 1 0 0 1 1 1]\n",
      "3 + 100 = 103\n",
      "------------\n",
      "Error:[ 0.08233386]\n",
      "Pred:[1 0 0 1 0 0 1 1]\n",
      "True:[1 0 0 1 0 0 1 1]\n",
      "96 + 51 = 147\n",
      "------------\n",
      "Error:[ 0.04494955]\n",
      "Pred:[0 0 1 1 0 1 0 1]\n",
      "True:[0 0 1 1 0 1 0 1]\n",
      "33 + 20 = 53\n",
      "------------\n",
      "Error:[ 0.09322714]\n",
      "Pred:[0 1 0 0 1 1 1 1]\n",
      "True:[0 1 0 0 1 1 1 1]\n",
      "63 + 16 = 79\n",
      "------------\n",
      "Error:[ 0.10684309]\n",
      "Pred:[0 1 0 0 1 0 1 0]\n",
      "True:[0 1 0 0 1 0 1 0]\n",
      "30 + 44 = 74\n",
      "------------\n",
      "Error:[ 0.05027123]\n",
      "Pred:[0 0 0 1 1 0 1 1]\n",
      "True:[0 0 0 1 1 0 1 1]\n",
      "16 + 11 = 27\n",
      "------------\n",
      "Error:[ 0.09845153]\n",
      "Pred:[0 1 1 0 0 0 0 0]\n",
      "True:[0 1 1 0 0 0 0 0]\n",
      "65 + 31 = 96\n",
      "------------\n",
      "Error:[ 0.07854209]\n",
      "Pred:[1 0 1 1 1 0 1 0]\n",
      "True:[1 0 1 1 1 0 1 0]\n",
      "115 + 71 = 186\n",
      "------------\n",
      "Error:[ 0.07859761]\n",
      "Pred:[0 1 1 1 0 0 0 0]\n",
      "True:[0 1 1 1 0 0 0 0]\n",
      "5 + 107 = 112\n",
      "------------\n",
      "Error:[ 0.09946721]\n",
      "Pred:[1 0 0 0 1 0 0 0]\n",
      "True:[1 0 0 0 1 0 0 0]\n",
      "17 + 119 = 136\n",
      "------------\n",
      "Error:[ 0.08508775]\n",
      "Pred:[1 0 0 1 1 0 0 0]\n",
      "True:[1 0 0 1 1 0 0 0]\n",
      "68 + 84 = 152\n",
      "------------\n",
      "Error:[ 0.08932008]\n",
      "Pred:[1 1 1 0 1 0 0 0]\n",
      "True:[1 1 1 0 1 0 0 0]\n",
      "107 + 125 = 232\n",
      "------------\n",
      "Error:[ 0.11040851]\n",
      "Pred:[1 0 0 1 0 0 0 1]\n",
      "True:[1 0 0 1 0 0 0 1]\n",
      "43 + 102 = 145\n",
      "------------\n",
      "Error:[ 0.05305938]\n",
      "Pred:[0 1 0 1 1 1 0 0]\n",
      "True:[0 1 0 1 1 1 0 0]\n",
      "23 + 69 = 92\n",
      "------------\n",
      "Error:[ 0.10292634]\n",
      "Pred:[1 0 0 0 0 0 1 1]\n",
      "True:[1 0 0 0 0 0 1 1]\n",
      "15 + 116 = 131\n",
      "------------\n",
      "Error:[ 0.09401289]\n",
      "Pred:[1 1 1 0 0 0 1 1]\n",
      "True:[1 1 1 0 0 0 1 1]\n",
      "108 + 119 = 227\n",
      "------------\n",
      "Error:[ 0.08167143]\n",
      "Pred:[0 1 0 0 1 1 1 1]\n",
      "True:[0 1 0 0 1 1 1 1]\n",
      "27 + 52 = 79\n",
      "------------\n",
      "Error:[ 0.0960896]\n",
      "Pred:[1 0 0 1 0 0 1 1]\n",
      "True:[1 0 0 1 0 0 1 1]\n",
      "121 + 26 = 147\n",
      "------------\n",
      "Error:[ 0.06742156]\n",
      "Pred:[1 0 1 1 0 1 1 0]\n",
      "True:[1 0 1 1 0 1 1 0]\n",
      "114 + 68 = 182\n",
      "------------\n",
      "Error:[ 0.04795639]\n",
      "Pred:[0 1 0 1 1 1 1 0]\n",
      "True:[0 1 0 1 1 1 1 0]\n",
      "30 + 64 = 94\n",
      "------------\n",
      "Error:[ 0.06058081]\n",
      "Pred:[1 0 0 1 1 0 1 1]\n",
      "True:[1 0 0 1 1 0 1 1]\n",
      "64 + 91 = 155\n",
      "------------\n",
      "Error:[ 0.08649649]\n",
      "Pred:[1 0 1 1 0 0 1 0]\n",
      "True:[1 0 1 1 0 0 1 0]\n",
      "122 + 56 = 178\n",
      "------------\n",
      "Error:[ 0.04192939]\n",
      "Pred:[0 0 1 0 1 0 1 1]\n",
      "True:[0 0 1 0 1 0 1 1]\n",
      "11 + 32 = 43\n",
      "------------\n",
      "Error:[ 0.06527694]\n",
      "Pred:[0 0 1 1 0 1 0 0]\n",
      "True:[0 0 1 1 0 1 0 0]\n",
      "29 + 23 = 52\n",
      "------------\n",
      "Error:[ 0.05695444]\n",
      "Pred:[0 0 1 0 1 1 1 1]\n",
      "True:[0 0 1 0 1 1 1 1]\n",
      "38 + 9 = 47\n",
      "------------\n",
      "Error:[ 0.04916875]\n",
      "Pred:[0 1 1 1 1 1 1 0]\n",
      "True:[0 1 1 1 1 1 1 0]\n",
      "74 + 52 = 126\n",
      "------------\n",
      "Error:[ 0.08403528]\n",
      "Pred:[0 1 0 0 1 1 0 1]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "22 + 55 = 77\n",
      "------------\n",
      "Error:[ 0.06995407]\n",
      "Pred:[0 0 1 0 1 0 1 1]\n",
      "True:[0 0 1 0 1 0 1 1]\n",
      "12 + 31 = 43\n",
      "------------\n",
      "Error:[ 0.08218885]\n",
      "Pred:[1 1 0 0 1 0 0 0]\n",
      "True:[1 1 0 0 1 0 0 0]\n",
      "109 + 91 = 200\n",
      "------------\n",
      "Error:[ 0.09615282]\n",
      "Pred:[1 1 0 0 0 0 0 1]\n",
      "True:[1 1 0 0 0 0 0 1]\n",
      "66 + 127 = 193\n",
      "------------\n",
      "Error:[ 0.09413433]\n",
      "Pred:[1 0 1 0 1 0 0 1]\n",
      "True:[1 0 1 0 1 0 0 1]\n",
      "126 + 43 = 169\n",
      "------------\n",
      "Error:[ 0.0856939]\n",
      "Pred:[1 0 1 0 0 1 1 0]\n",
      "True:[1 0 1 0 0 1 1 0]\n",
      "47 + 119 = 166\n",
      "------------\n",
      "Error:[ 0.03828664]\n",
      "Pred:[0 1 0 0 1 1 0 0]\n",
      "True:[0 1 0 0 1 1 0 0]\n",
      "1 + 75 = 76\n",
      "------------\n",
      "Error:[ 0.07189659]\n",
      "Pred:[0 1 1 1 1 0 0 1]\n",
      "True:[0 1 1 1 1 0 0 1]\n",
      "85 + 36 = 121\n",
      "------------\n",
      "Error:[ 0.0576181]\n",
      "Pred:[1 0 1 1 1 1 0 1]\n",
      "True:[1 0 1 1 1 1 0 1]\n",
      "76 + 113 = 189\n",
      "------------\n",
      "Error:[ 0.09219935]\n",
      "Pred:[1 0 0 0 1 0 1 1]\n",
      "True:[1 0 0 0 1 0 1 1]\n",
      "76 + 63 = 139\n",
      "------------\n",
      "Error:[ 0.09400036]\n",
      "Pred:[1 0 1 0 0 0 1 1]\n",
      "True:[1 0 1 0 0 0 1 1]\n",
      "69 + 94 = 163\n",
      "------------\n",
      "Error:[ 0.08295298]\n",
      "Pred:[1 1 0 1 1 0 1 0]\n",
      "True:[1 1 0 1 1 0 1 0]\n",
      "110 + 108 = 218\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# training logic\n",
    "# 学习10000个例子\n",
    "for j in range(100000):\n",
    "    \n",
    "    # 下面6行代码，随机产生两个0-128的数字，并查出他们的二进制表示。为了避免相加之和超过256，这里选择两个0-128的数字\n",
    "    # generate a simple addition problem (a + b = c)\n",
    "    a_int = np.random.randint(largest_number/2) # int version\n",
    "    a = int2binary[a_int] # binary encoding\n",
    "    b_int = np.random.randint(largest_number/2) # int version\n",
    "    b = int2binary[b_int] # binary encoding\n",
    "    # true answer\n",
    "    c_int = a_int + b_int\n",
    "    c = int2binary[c_int]\n",
    "    \n",
    "    # where we'll store our best guess (binary encoded)\n",
    "    # 存储神经网络的预测值\n",
    "    d = np.zeros_like(c)\n",
    "    overallError = 0 #每次把总误差清零\n",
    "    \n",
    "    layer_2_deltas = list() #存储每个时间点输出层的误差\n",
    "    layer_1_values = list() #存储每个时间点隐藏层的值\n",
    "    layer_1_values.append(np.zeros(hidden_dim)) #一开始没有隐藏层，所以里面都是0\n",
    "    \n",
    "    # moving along the positions in the binary encoding\n",
    "    for position in range(binary_dim):#循环遍历每一个二进制位\n",
    "        \n",
    "        # generate input and output\n",
    "        X = np.array([[a[binary_dim - position - 1],b[binary_dim - position - 1]]])#从右到左，每次去两个输入数字的一个bit位\n",
    "        y = np.array([[c[binary_dim - position - 1]]]).T#正确答案\n",
    "        # hidden layer (input ~+ prev_hidden)\n",
    "        layer_1 = sigmoid(np.dot(X,synapse_0) + np.dot(layer_1_values[-1],synapse_h))#（输入层 + 之前的隐藏层） -> 新的隐藏层，这是体现循环神经网络的最核心的地方！！！\n",
    "        # output layer (new binary representation)\n",
    "        layer_2 = sigmoid(np.dot(layer_1,synapse_1)) #隐藏层 * 隐藏层到输出层的转化矩阵synapse_1 -> 输出层\n",
    "        # did we miss?... if so, by how much?\n",
    "        layer_2_error = y - layer_2 #预测误差是多少\n",
    "        layer_2_deltas.append((layer_2_error)*sigmoid_output_to_derivative(layer_2)) #我们把每一个时间点的误差导数都记录下来\n",
    "        overallError += np.abs(layer_2_error[0])#总误差\n",
    "    \n",
    "        # decode estimate so we can print it out\n",
    "        d[binary_dim - position - 1] = np.round(layer_2[0][0]) #记录下每一个预测bit位\n",
    "        \n",
    "        # store hidden layer so we can use it in the next timestep\n",
    "        layer_1_values.append(copy.deepcopy(layer_1))#记录下隐藏层的值，在下一个时间点用\n",
    "    \n",
    "    future_layer_1_delta = np.zeros(hidden_dim)\n",
    "    \n",
    "    #前面代码我们完成了所有时间点的正向传播以及计算最后一层的误差，现在我们要做的是反向传播，从最后一个时间点到第一个时间点\n",
    "    for position in range(binary_dim):\n",
    "        \n",
    "        X = np.array([[a[position],b[position]]]) #最后一次的两个输入\n",
    "        layer_1 = layer_1_values[-position-1] #当前时间点的隐藏层\n",
    "        prev_layer_1 = layer_1_values[-position-2] #前一个时间点的隐藏层\n",
    "        \n",
    "        # error at output layer\n",
    "        layer_2_delta = layer_2_deltas[-position-1] #当前时间点输出层导数\n",
    "        # error at hidden layer\n",
    "        # 通过后一个时间点（因为是反向传播）的隐藏层误差和当前时间点的输出层误差，计算当前时间点的隐藏层误差\n",
    "        layer_1_delta = (future_layer_1_delta.dot(synapse_h.T) + layer_2_delta.dot(synapse_1.T)) * sigmoid_output_to_derivative(layer_1)\n",
    "        # let's update all our weights so we can try again\n",
    "        # 我们已经完成了当前时间点的反向传播误差计算， 可以构建更新矩阵了。但是我们并不会现在就更新权重矩阵，因为我们还要用他们计算前一个时间点的更新矩阵呢。\n",
    "        # 所以要等到我们完成了所有反向传播误差计算， 才会真正的去更新权重矩阵，我们暂时把更新矩阵存起来。\n",
    "        # 可以看这里了解更多关于反向传播的知识http://iamtrask.github.io/2015/07/12/basic-python-network/\n",
    "        synapse_1_update += np.atleast_2d(layer_1).T.dot(layer_2_delta)\n",
    "        synapse_h_update += np.atleast_2d(prev_layer_1).T.dot(layer_1_delta)\n",
    "        synapse_0_update += X.T.dot(layer_1_delta)\n",
    "        \n",
    "        future_layer_1_delta = layer_1_delta\n",
    "    \n",
    "    # 我们已经完成了所有的反向传播，可以更新几个转换矩阵了。并把更新矩阵变量清零\n",
    "    synapse_0 += synapse_0_update * alpha\n",
    "    synapse_1 += synapse_1_update * alpha\n",
    "    synapse_h += synapse_h_update * alpha\n",
    "    synapse_0_update *= 0\n",
    "    synapse_1_update *= 0\n",
    "    synapse_h_update *= 0\n",
    "    \n",
    "    # print out progress\n",
    "    if(j % 2000 == 0):\n",
    "        print(\"Error:\" + str(overallError))\n",
    "        print(\"Pred:\" + str(d))\n",
    "        print(\"True:\" + str(c))\n",
    "        out = 0\n",
    "        for index,x in enumerate(reversed(d)):\n",
    "            out += x*pow(2,index)\n",
    "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out))\n",
    "        print(\"------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
