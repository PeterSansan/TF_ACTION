{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TensorFlow基本操作\n",
    "```\n",
    "Author: PeterSansan\n",
    "Project: https://github.com/PeterSansan/TF_ACTION\n",
    "Time : 2017.04.25\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [目录]\n",
    "- [1、算法运算比较GPU与CPU的性能](#1) \n",
    "- [2、另一种会话形式](#2)\n",
    "- [3、assign赋值函数](#3)\n",
    "- [4、fetch取数据 ](#4)\n",
    "- [5、feed填数据](#5) \n",
    "- [6、get_variable与Variable的一点区别](#6)\n",
    "- [7、argmax](#7)\n",
    "- [8、dropout](#8)\n",
    "- [9、保存数据](#9)\n",
    "- [10、读取数据](#10)\n",
    "- [11、变量的赋值不要用run](#11)\n",
    "- [12、print输出到文件](#12)\n",
    "- [13、初始化函数](#13)\n",
    "- [14、命名域与共享变量](#14)\n",
    "- [15、查看CPU与GPU使用情况](#15)\n",
    "- [16. tf.reshape](#16)\n",
    "- [17.tf.transpose](#17)\n",
    "- [18.tf.gather](#18)\n",
    "- [19.加减乘除](#19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"1\">1.乘法运算比较GPU与CPU的性能</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spend time 0.521105 s\n"
     ]
    }
   ],
   "source": [
    "begin=time.time() # 时间开始\n",
    "with tf.Session() as sess0:\n",
    "    with tf.device(\"/gpu:0\"):#g 不加这个话就不能控制用CPU还是GPU，默认是GPU\n",
    "        matrix1 = np.random.rand(1000,1500).astype(np.float32)\n",
    "        matrix2 = np.random.rand(1500,1000).astype(np.float32)\n",
    "        product = tf.matmul(matrix1, matrix2)\n",
    "        result = sess0.run(product)\n",
    "\n",
    "end = time.time()  # 时间结束\n",
    "print(\"Spend time %f s\" %(end - begin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spend time 0.111130 s\n"
     ]
    }
   ],
   "source": [
    "begin=time.time() # 时间开始\n",
    "with tf.Session() as sess0:\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        matrix1 = np.random.rand(1000,1500).astype(np.float32)\n",
    "        matrix2 = np.random.rand(1500,1000).astype(np.float32)\n",
    "        product = tf.matmul(matrix1, matrix2)\n",
    "        result = sess0.run(product)\n",
    "\n",
    "end = time.time()  # 时间结束\n",
    "print(\"Spend time %f s\" %(end - begin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面跑出来的结果可以看出GPU比CPU要快一些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"2\">2.另一种会话形式</span>\n",
    "前面那种会话是在模型与数据准备好的情况下，开启会话的，一般用`with tf.Session() as sess:`包含在里面，其实还有另外一种交互式更多好的会话形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 36.421978    32.33883667  36.32481384 ...,  38.8259964   36.90905762\n",
      "   34.96734619]\n",
      " [ 33.61271286  32.13290787  36.21008682 ...,  37.74457169  35.23854065\n",
      "   32.92845154]\n",
      " [ 33.85023117  35.27126312  38.10679626 ...,  40.34016418  36.56521225\n",
      "   34.90681839]\n",
      " ..., \n",
      " [ 35.16938782  31.14734268  36.21683884 ...,  39.2146225   36.79617691\n",
      "   33.15740204]\n",
      " [ 35.17005539  32.75048828  37.8230629  ...,  39.10813522  37.65684509\n",
      "   36.33364487]\n",
      " [ 39.25868225  38.5942421   42.88594818 ...,  45.04597855  39.78922653\n",
      "   38.75571442]]\n"
     ]
    }
   ],
   "source": [
    "#deploy a session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#design the grape\n",
    "matrix1 = np.random.rand(200,150).astype(np.float32)\n",
    "matrix2 = np.random.rand(150,200).astype(np.float32)\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "#run the operation\n",
    "print(product.eval())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span id=\"3\">3.assign赋值函数</span>\n",
    "实现了计算器功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#design the graph\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)  #赋值\n",
    "\n",
    "#initialization\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "#run \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(state))\n",
    "    for _ in range(4):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"4\">4.fetch取数据</span>\n",
    "这种方法实际上我们上面一直在用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.0, 7.0]\n",
      "[7.0]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)    # 定义三个常量\n",
    "\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([mul, intermed])\n",
    "    print(result)  # 取两个结果\n",
    "    result = sess.run([intermed])\n",
    "    print(result)   # 取一个结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"5\">5.feed填数据</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3.,  3.,  3.],\n",
      "       [ 3.,  3.,  3.],\n",
      "       [ 3.,  3.,  3.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.placeholder(tf.float32,shape=(3, 3))\n",
    "input2 = tf.placeholder(tf.float32,shape=(3, 3))\n",
    "output = tf.matmul(input1, input2)#matmul is different mul\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    rand_array = np.ones([3, 3])\n",
    "    print(sess.run([output], feed_dict={input1: rand_array,input2: rand_array}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"6\">6.get_variable与Variable的一点区别</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'counter:0' shape=() dtype=int32_ref>, <tf.Variable 'a:0' shape=(5, 2) dtype=float32_ref>, <tf.Variable 'd:0' shape=(3, 3) dtype=float32_ref>]\n",
      "[u'counter:0', u'a:0', u'd:0']\n",
      "[0,\n",
      " array([[-0.27231044,  0.06231701],\n",
      "       [-0.35887122, -0.00479323],\n",
      "       [ 0.88638067,  0.00665551],\n",
      "       [ 0.86526895,  0.58776093],\n",
      "       [ 0.42452621, -0.14003772]], dtype=float32),\n",
      " array([[ 0.24965227,  0.57588422,  0.70700598],\n",
      "       [ 0.53583944,  0.47054195,  0.7503984 ],\n",
      "       [ 0.63531339,  0.04223645,  0.30189431]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "\n",
    "a = tf.get_variable('a',shape=[5,2])    # 默认 trainable=True\n",
    "b = tf.get_variable('b',shape=[2,5],trainable=False)\n",
    "c = tf.constant([1,2,3],dtype=tf.int32,shape=[8],name='c') # 因为是常量，所以trainable=False\n",
    "d = tf.Variable(tf.random_uniform(shape=[3,3]),name='d')\n",
    "\n",
    "tvar = tf.trainable_variables()\n",
    "tvar_name = [x.name for x in tvar]\n",
    "print(tvar)\n",
    "# [<tensorflow.python.ops.variables.Variable object at 0x7f9c8db8ca20>, <tensorflow.python.ops.variables.Variable object at 0x7f9c8db8c9b0>]\n",
    "print(tvar_name)\n",
    "# ['a:0', 'd:0']\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pprint(sess.run(tvar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"7\">7.argmax</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.61477041  0.69772601 -0.34471726 -0.8610878 ]\n",
      " [ 0.45801592 -0.23750687  0.25103879 -0.94248724]\n",
      " [ 0.09553599  0.11336613  0.11424232 -0.7961154 ]]\n",
      "[0 0 1 2]\n",
      "[1 0 2]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "aa = tf.get_variable(name = 'aa',\n",
    "                    shape=[3,4],\n",
    "                    dtype = tf.float32,\n",
    "                    initializer=tf.random_uniform_initializer(minval=-1,maxval=1))\n",
    "\n",
    "bb = tf.argmax(input = aa,dimension = 0) # 选出每列中最大值的位置\n",
    "cc = tf.argmax(input = aa,dimension = 1) # 选出每行中最大值的位置\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(aa))\n",
    "print(sess.run(bb))\n",
    "print(sess.run(cc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span id=\"8\">8、dropout</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.18207711  0.49687707  0.60756719 -0.61472207  0.61041605]\n",
      " [-0.88965237 -0.68719679 -0.12012607  0.69617593 -0.75358987]]\n",
      "[[-0.          0.          0.75945896 -0.76840258  0.76302004]\n",
      " [-1.11206543 -0.85899597 -0.15015759  0.         -0.94198734]]\n",
      "[[-0.18207711  0.49687707  0.60756719 -0.61472207  0.61041605]\n",
      " [-0.88965237 -0.68719679 -0.12012607  0.69617593 -0.75358987]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "ai = tf.get_variable('ai',shape=[2,5])\n",
    "bi = ai\n",
    "ci = ai\n",
    "a_drop = tf.nn.dropout(ai,0.8)\n",
    "c_drop = tf.nn.dropout(ci,1)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(sess.run(ai))\n",
    "print(sess.run(a_drop))\n",
    "print(sess.run(c_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"9\">9、保存数据</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to path: ./save_par/save_par.ckpt\n",
      "weights: [[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]]\n",
      "biases: [[ 1.  2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# save to file  \n",
    "# 下面代码注释掉，因为一个文件保存与读取不要重复了\n",
    "W = tf.Variable([[1,2,3],[4,5,6]],dtype = tf.float32,name='weight')  \n",
    "b = tf.Variable([[1,2,3]],dtype = tf.float32,name='biases')  \n",
    "  \n",
    "init = tf.global_variables_initializer()  \n",
    "saver = tf.train.Saver()  \n",
    "with tf.Session() as sess:  \n",
    "    sess.run(init)  \n",
    "    save_path = saver.save(sess,\"./save_par/save_par.ckpt\")  \n",
    "    print (\"save to path:\",save_path)  \n",
    "    print (\"weights:\",sess.run(W))  \n",
    "    print (\"biases:\",sess.run(b)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"10\">10、加载数据</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "#W = tf.Variable(np.arange(6).reshape((2,3)),dtype = tf.float32,name='weight')  \n",
    "#b = tf.Variable(np.arange(3).reshape((1,3)),dtype = tf.float32,name='biases')  \n",
    "  \n",
    "#saver = tf.train.Saver()  \n",
    "#with tf.Session() as sess:  \n",
    "#        saver.restore(sess,\"./save_par/save_par.ckpt\")  \n",
    "#        print (\"weights:\",sess.run(W))  \n",
    "#        print (\"biases:\",sess.run(b))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"11\">11、变量的赋值不要用run</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "通过sess.run的方式读变量所需的时间: 1.00298500061\n",
      "通过直接赋值的手段读变量所需的时间: 0.000418901443481\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "t1 = time.time()  \n",
    "x = tf.Variable([1.0])  \n",
    "b =1.0  \n",
    "start1 = time.time()  \n",
    "with tf.Session() as sess:  \n",
    "    sess.run(tf.global_variables_initializer())  \n",
    "    #通过sess.run的方式读变量  \n",
    "    for step in range(5000):  \n",
    "        res = sess.run(x)  \n",
    "    print(\"通过sess.run的方式读变量所需的时间:\",time.time()-start1)  \n",
    "    start2 = time.time()  \n",
    "    for step in range(5000):  \n",
    "        a = b  \n",
    "    print(\"通过直接赋值的手段读变量所需的时间:\",time.time()-start2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"12\">12、print输出到文件</span>\n",
    "这个功能不是TensorFlow的，放在这里只是它也很常用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello weird\n",
      "Hello weird\n",
      "Hello weird\n",
      "Hello weird\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f=open('a.txt','a+') # 追加\n",
    "\n",
    "old=sys.stdout #将当前系统输出储存到一个临时变量中\n",
    "sys.stdout=f  #输出重定向到文件\n",
    "print('Hello weird') #测试一个打印输出\n",
    "sys.stdout.flush() # 刷新文件流\n",
    "sys.stdout=old #还原原系统输出\n",
    "f.close() \n",
    "print(open('a.txt','r').read())\n",
    "\n",
    "# 第二种方法\n",
    "# f=open('test.txt','a+')\n",
    "# s= '123'\n",
    "# abc= '456'\n",
    "# print >> f, s,abc\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_basic_operations.ipynb       4_tensorboard_advanced.ipynb\r\n",
      "2_nearest_neighbor.ipynb       4_tensorboard_basic.ipynb\r\n",
      "3_autoencoder.ipynb            a.txt\r\n",
      "3_bidirectional_rnn.ipynb      every_rnn.ipynb\r\n",
      "3_convolutional_network.ipynb  linear_regression.ipynb\r\n",
      "3_dynamic_rnn.ipynb            logistic_regression.ipynb\r\n",
      "3_multilayer_perceptron.ipynb  README.md\r\n",
      "3_recurrent_network_1.ipynb    \u001b[0m\u001b[01;34msave_par\u001b[0m/\r\n",
      "3_recurrent_network.ipynb      tensorboard_advanced.py\r\n",
      "4_save_restore_model.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"13\">13、使用初始化函数</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting shape:\n",
      "[[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]]\n"
     ]
    }
   ],
   "source": [
    "value = [0,1,2,3,4,5,6,7]\n",
    "#value = np.array(value)  # 注释掉没有影响\n",
    "#value = value.reshape([2,4])\n",
    "init = tf.constant_initializer(value)\n",
    "print('fitting shape:')\n",
    "tf.reset_default_graph()\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[2,4],initializer=init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "larger shape:\n",
      "[[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]\n",
      " [ 7.  7.  7.  7.]]\n"
     ]
    }
   ],
   "source": [
    "print('larger shape:')  #小型的初始化是不允许的，也就是说shape小于原来的大小\n",
    "tf.reset_default_graph()\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[3,4],initializer = init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_normal_initializer:\n",
      "[[ 0.95753425  1.46059477  0.27371508  0.36605692]\n",
      " [ 0.24621746 -0.02094328 -0.25224099  0.35705945]\n",
      " [ 0.50815475 -0.28746808 -1.14822376  0.85695541]]\n"
     ]
    }
   ],
   "source": [
    "print('random_normal_initializer:')\n",
    "tf.reset_default_graph()\n",
    "init = tf.random_normal_initializer(mean=0.0,stddev=1.0) #正态分布函数\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[3,4],initializer = init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truncated_normal_initializer:\n",
      "[[-1.21936464 -1.09728968 -0.22761106  0.29304495]\n",
      " [ 0.48207191 -1.66472459  0.04900533 -0.65437996]\n",
      " [-0.24525788 -0.32525098 -1.25320446 -0.09456635]]\n"
     ]
    }
   ],
   "source": [
    "print('truncated_normal_initializer:')\n",
    "tf.reset_default_graph()\n",
    "init = tf.truncated_normal_initializer(mean=0.0,stddev=1.0)\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[3,4],initializer = init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_uniform_initializer:\n",
      "[[ 0.03791809  0.5784198   0.27508795  0.93115556]\n",
      " [ 0.49908543  0.26265407  0.89508104  0.17106414]\n",
      " [ 0.57495534  0.98303199  0.7831167   0.26729894]]\n"
     ]
    }
   ],
   "source": [
    "print('random_uniform_initializer:')\n",
    "tf.reset_default_graph()\n",
    "init = tf.random_uniform_initializer(minval=0,maxval=None) #均匀分布随机数\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[3,4],initializer = init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "【说明】：\n",
    "tf.random_normal | tf.truncated_normal | tf.random_uniform\n",
    "tf.random_normal(shape,mean=0.0,stddev=1.0,dtype=tf.float32,seed=None,name=None)\n",
    "tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "tf.random_uniform(shape,minval=0,maxval=None,dtype=tf.float32,seed=None,name=None)\n",
    "这几个都是用于生成随机数tensor的。尺寸是shape\n",
    "random_normal: 正太分布随机数，均值mean,标准差stddev\n",
    "truncated_normal:截断正态分布随机数，均值mean,标准差stddev,不过只保留[mean-2*stddev,mean+2*stddev]范围内的随机数\n",
    "random_uniform:均匀分布随机数，范围为[minval,maxval]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"14\">14、命名域与共享变量</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo/bar/v:0\n",
      "foo/bar/v:0\n",
      "foo1/bar1/v:0\n",
      "foo1/bar1/v:0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "# 不同的命名域与变量\n",
    "with tf.variable_scope(\"foo\"):\n",
    "  with tf.variable_scope(\"bar\"):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    print(v.name)\n",
    "\n",
    "print(v.name)\n",
    "\n",
    "with tf.variable_scope(\"foo1\"):\n",
    "  with tf.variable_scope(\"bar1\"):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    print(v.name)\n",
    "print(v.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'xxx/a:0' shape=(1,) dtype=float32_ref> <tf.Variable 'xxx/a:0' shape=(1,) dtype=float32_ref>\n",
      "[-0.40943015] [-0.40943015]\n"
     ]
    }
   ],
   "source": [
    "# 变量共享（相同变量）\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "with tf.variable_scope(\"xxx\"):\n",
    "  a = tf.get_variable(\"a\",[1])\n",
    "with tf.variable_scope(\"xxx\",reuse=True):   # 采用xxx/a的值\n",
    "  a1 = tf.get_variable(\"a\",[1])\n",
    "print(a,a1)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(a.eval(),a1.eval()) #如果初始化为None,则会采用variable_scope的初始化值，\n",
    "# 如果也是None,则采用uniform_unit_scaling_initializer\n",
    "assert a==a1  # a , a1 是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 变量共享（相同变量）另一种写法\n",
    "tf.reset_default_graph()\n",
    "with tf.variable_scope(\"yyy\") as scope:\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    scope.reuse_variables()\n",
    "    v1 = tf.get_variable(\"v\", [1])\n",
    "assert v1 == v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 为防止在没有使用reuse的情况下出现相现的共享变量，则会弹出异常,如下面是有错误的\n",
    "# with tf.variable_scope(\"zzz\"):\n",
    "  # v = tf.get_variable(\"v\",[1])\n",
    "  # v1 = tf.get_variable(\"v\",[1])\n",
    "  # Raises ValueError(\"...v already exists ...\").\n",
    "  \n",
    "# 为防止在使用reuse的情况下引用了之前没有的共享变量，则会弹出异常，如下面是有错误的\n",
    "# with tf.variable_scope(\"aaa\",reuse=True):\n",
    "  # v = tf.get_variable(\"v\",[1])\n",
    "  # Raises ValueError(\"... v does not exists...\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"15\">15.查看CPU与GPU使用</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CPU:\n",
    "    sensors   or   watch sensors\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "GPU:\n",
    "    nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader\n",
    "    or \n",
    "    nvidia-smi -a  # 可以看到显示的所有信息，包括什么温度会关自动关闭\n",
    "    or\n",
    "    watch -n 1 nvidia-smi  # 1秒的频率\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"16\">16.tf.reshape</span>\n",
    "```\n",
    "tf.reshape(tensor,shape,name=None)\n",
    "\n",
    "顾名思义，就是将tensor按照新的shape重新排列。一般来说，shape有三种用法： \n",
    "如果 shape=[-1], 表示要将tensor展开成一个list \n",
    "如果 shape=[a,b,c,…] 其中每个a,b,c,..均>0，那么就是常规用法 \n",
    "如果 shape=[a,-1,c,…] 此时b=-1，a,c,..依然>0。这表示tf会根据tensor的原尺寸，自动计算b的值。 \n",
    "官方给的例子已经很详细了，我就不写示例代码了\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# 官方例子\n",
    "# tensor 't' is [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "# tensor 't' has shape [9]\n",
    "reshape(t, [3, 3]) ==> [[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]]\n",
    "\n",
    "# tensor 't' is [[[1, 1], [2, 2]],\n",
    "#                [[3, 3], [4, 4]]]\n",
    "# tensor 't' has shape [2, 2, 2]\n",
    "reshape(t, [2, 4]) ==> [[1, 1, 2, 2],\n",
    "                        [3, 3, 4, 4]]\n",
    "\n",
    "# tensor 't' is [[[1, 1, 1],\n",
    "#                 [2, 2, 2]],\n",
    "#                [[3, 3, 3],\n",
    "#                 [4, 4, 4]],\n",
    "#                [[5, 5, 5],\n",
    "#                 [6, 6, 6]]]\n",
    "# tensor 't' has shape [3, 2, 3]\n",
    "# pass '[-1]' to flatten 't'\n",
    "reshape(t, [-1]) ==> [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]\n",
    "\n",
    "# -1 can also be used to infer the shape\n",
    "# -1 is inferred to be 9:\n",
    "reshape(t, [2, -1]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]\n",
    "\n",
    "# -1 is inferred to be 2:\n",
    "reshape(t, [-1, 9]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]\n",
    "\n",
    "# -1 is inferred to be 3:\n",
    "reshape(t, [ 2, -1, 3]) ==> [[[1, 1, 1],\n",
    "                              [2, 2, 2],\n",
    "                              [3, 3, 3]],\n",
    "                             [[4, 4, 4],\n",
    "                              [5, 5, 5],\n",
    "                              [6, 6, 6]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"17\">17.tf.transpose</span>\n",
    "转置函数：\n",
    "\n",
    "转见：[csdn](http://blog.csdn.net/u010417185/article/details/51900441)\n",
    "\n",
    "### <span id = \"18\">18.tf.gather</span>\n",
    "筛选函数：\n",
    "\n",
    "转见：[csdn](http://blog.csdn.net/guotong1988/article/details/53172882)\n",
    "\n",
    "### <span id = \"19\">19.加减乘除</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtracting a from b: 1.0\n",
      "Adding a and b: 12.0\n",
      "Multiplying a and b: 35.75\n",
      "Dividing a and b: 1.18182\n",
      "Floor dividing a and b: 1.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.constant(5.5)\n",
    "b = tf.constant(6.5)\n",
    "sess = tf.InteractiveSession()\n",
    "print(\"Subtracting a from b:\",sess.run(tf.subtract(b, a)))\n",
    "print(\"Adding a and b:\",sess.run(tf.add(a, b)))\n",
    "print(\"Multiplying a and b:\",sess.run(tf.multiply(a, b)))\n",
    "print(\"Dividing a and b:\",sess.run(tf.divide(b, a)))\n",
    "print(\"Floor dividing a and b:\",sess.run(tf.floor_div(b, a)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
