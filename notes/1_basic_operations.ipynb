{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TensorFlow基本操作\n",
    "```\n",
    "Author: PeterSansan\n",
    "Project: https://github.com/PeterSansan/TF_ACTION\n",
    "Time : 2017.04.25\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [目录]\n",
    "- [1、算法运算比较GPU与CPU的性能](#1) \n",
    "- [2、另一种会话形式](#2)\n",
    "- [3、assign赋值函数](#3)\n",
    "- [4、fetch取数据 ](#4)\n",
    "- [5、feed填数据](#5) \n",
    "- [6、get_variable与Variable的一点区别](#6)\n",
    "- [7、argmax](#7)\n",
    "- [8、dropout](#8)\n",
    "- [9、保存数据](#9)\n",
    "- [10、读取数据](#10)\n",
    "- [11、变量的赋值不要用run](#11)\n",
    "- [12、print输出到文件](#12)\n",
    "- [13、初始化函数](#13)\n",
    "- [14、命名域与共享变量](#14)\n",
    "- [15、查看CPU与GPU使用情况](#15)\n",
    "- [16. tf.reshape](#16)\n",
    "- [17.tf.transpose](#17)\n",
    "- [18.tf.gather](#18)\n",
    "- [19.加减乘除](#19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"1\">1.乘法运算比较GPU与CPU的性能</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spend time 3.600356 s\n"
     ]
    }
   ],
   "source": [
    "begin=time.time() # 时间开始\n",
    "with tf.Session() as sess0:\n",
    "    with tf.device(\"/gpu:0\"):#g 不加这个话就不能控制用CPU还是GPU，默认是GPU\n",
    "        matrix1 = np.random.rand(1000,1500).astype(np.float32)\n",
    "        matrix2 = np.random.rand(1500,1000).astype(np.float32)\n",
    "        product = tf.matmul(matrix1, matrix2)\n",
    "        result = sess0.run(product)\n",
    "\n",
    "end = time.time()  # 时间结束\n",
    "print(\"Spend time %f s\" %(end - begin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spend time 0.115566 s\n"
     ]
    }
   ],
   "source": [
    "begin=time.time() # 时间开始\n",
    "with tf.Session() as sess0:\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        matrix1 = np.random.rand(1000,1500).astype(np.float32)\n",
    "        matrix2 = np.random.rand(1500,1000).astype(np.float32)\n",
    "        product = tf.matmul(matrix1, matrix2)\n",
    "        result = sess0.run(product)\n",
    "\n",
    "end = time.time()  # 时间结束\n",
    "print(\"Spend time %f s\" %(end - begin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">上面跑出来的结果可以看出GPU比CPU要快一些</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"2\">2.另一种会话形式</span>\n",
    "前面那种会话是在模型与数据准备好的情况下，开启会话的，一般用`with tf.Session() as sess:`包含在里面，其实还有另外一种交互式更多好的会话形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 33.65610123  34.5807457   32.51171112 ...,  31.12764931  38.69446945\n",
      "   36.99295807]\n",
      " [ 35.17318726  35.67451859  33.52633667 ...,  32.91594315  36.71580505\n",
      "   37.40443802]\n",
      " [ 37.40917969  38.15063858  35.33099747 ...,  36.77067184  41.51041412\n",
      "   38.43318939]\n",
      " ..., \n",
      " [ 39.80768585  38.88362503  37.45733261 ...,  35.96920013  42.38987732\n",
      "   40.98935699]\n",
      " [ 35.8903389   36.27746582  33.28411865 ...,  36.44659424  39.87301636\n",
      "   37.83668518]\n",
      " [ 35.47333527  36.97055817  32.76354218 ...,  33.64844894  36.50693893\n",
      "   37.90606689]]\n"
     ]
    }
   ],
   "source": [
    "#deploy a session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#design the grape\n",
    "matrix1 = np.random.rand(200,150).astype(np.float32)\n",
    "matrix2 = np.random.rand(150,200).astype(np.float32)\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "#run the operation\n",
    "print(product.eval())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span id=\"3\">3.assign赋值函数</span>\n",
    "实现了计算器功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#design the graph\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)  #赋值\n",
    "\n",
    "#initialization\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "#run \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(state))\n",
    "    for _ in range(4):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"4\">4.fetch取数据</span>\n",
    "这种方法实际上我们上面一直在用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.0, 7.0]\n",
      "[7.0]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)    # 定义三个常量\n",
    "\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([mul, intermed])\n",
    "    print(result)  # 取两个结果\n",
    "    result = sess.run([intermed])\n",
    "    print(result)   # 取一个结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"5\">5.feed填数据</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3.,  3.,  3.],\n",
      "       [ 3.,  3.,  3.],\n",
      "       [ 3.,  3.,  3.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.placeholder(tf.float32,shape=(3, 3))\n",
    "input2 = tf.placeholder(tf.float32,shape=(3, 3))\n",
    "output = tf.matmul(input1, input2)#matmul is different mul\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    rand_array = np.ones([3, 3])\n",
    "    print(sess.run([output], feed_dict={input1: rand_array,input2: rand_array}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"6\">6.get_variable与Variable的一点区别</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'counter:0' shape=() dtype=int32_ref>, <tf.Variable 'a:0' shape=(5, 2) dtype=float32_ref>, <tf.Variable 'd:0' shape=(3, 3) dtype=float32_ref>]\n",
      "[u'counter:0', u'a:0', u'd:0']\n",
      "[0,\n",
      " array([[ 0.91374362,  0.77542281],\n",
      "       [ 0.09192395, -0.7873472 ],\n",
      "       [ 0.77425361,  0.6774987 ],\n",
      "       [ 0.18611455,  0.53725147],\n",
      "       [ 0.66976511,  0.59764135]], dtype=float32),\n",
      " array([[ 0.98069656,  0.57469404,  0.34242105],\n",
      "       [ 0.81447363,  0.49137688,  0.24920309],\n",
      "       [ 0.08228135,  0.49962556,  0.02091193]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "\n",
    "a = tf.get_variable('a',shape=[5,2])    # 默认 trainable=True\n",
    "b = tf.get_variable('b',shape=[2,5],trainable=False)\n",
    "c = tf.constant([1,2,3],dtype=tf.int32,shape=[8],name='c') # 因为是常量，所以trainable=False\n",
    "d = tf.Variable(tf.random_uniform(shape=[3,3]),name='d')\n",
    "\n",
    "tvar = tf.trainable_variables()\n",
    "tvar_name = [x.name for x in tvar]\n",
    "print(tvar)\n",
    "# [<tensorflow.python.ops.variables.Variable object at 0x7f9c8db8ca20>, <tensorflow.python.ops.variables.Variable object at 0x7f9c8db8c9b0>]\n",
    "print(tvar_name)\n",
    "# ['a:0', 'd:0']\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pprint(sess.run(tvar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"7\">7.argmax</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-fdd27ef7ef87>:8: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "WARNING:tensorflow:From <ipython-input-9-fdd27ef7ef87>:9: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "[[ 0.60302591  0.72983623 -0.06742501  0.99034882]\n",
      " [-0.0453825  -0.3799901   0.69216585  0.25788927]\n",
      " [ 0.5958724   0.54000545  0.62644029  0.3175745 ]]\n",
      "[0 0 1 0]\n",
      "[3 2 2]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "aa = tf.get_variable(name = 'aa',\n",
    "                    shape=[3,4],\n",
    "                    dtype = tf.float32,\n",
    "                    initializer=tf.random_uniform_initializer(minval=-1,maxval=1))\n",
    "\n",
    "bb = tf.argmax(input = aa,dimension = 0) # 选出每列中最大值的位置\n",
    "cc = tf.argmax(input = aa,dimension = 1) # 选出每行中最大值的位置\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(aa))\n",
    "print(sess.run(bb))\n",
    "print(sess.run(cc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span id=\"8\">8、dropout</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.31626254  0.53986716  0.80050004  0.83001328 -0.18961602]\n",
      " [-0.92055213  0.56703258  0.28375387  0.16607571 -0.45236477]]\n",
      "[[-0.39532816  0.67483395  1.00062501  1.03751659 -0.        ]\n",
      " [-1.1506902   0.          0.35469234  0.20759463 -0.56545597]]\n",
      "[[-0.31626254  0.53986716  0.80050004  0.83001328 -0.18961602]\n",
      " [-0.92055213  0.56703258  0.28375387  0.16607571 -0.45236477]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "ai = tf.get_variable('ai',shape=[2,5])\n",
    "bi = ai\n",
    "ci = ai\n",
    "a_drop = tf.nn.dropout(ai,0.8)\n",
    "c_drop = tf.nn.dropout(ci,1)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(sess.run(ai))\n",
    "print(sess.run(a_drop))\n",
    "print(sess.run(c_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"9\">9、保存数据</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to path: ./save_par/save_par.ckpt\n",
      "weights: [[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]]\n",
      "biases: [[ 1.  2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# save to file  \n",
    "# 下面代码注释掉，因为一个文件保存与读取不要重复了\n",
    "W = tf.Variable([[1,2,3],[4,5,6]],dtype = tf.float32,name='weight')  \n",
    "b = tf.Variable([[1,2,3]],dtype = tf.float32,name='biases')  \n",
    "  \n",
    "init = tf.global_variables_initializer()  \n",
    "saver = tf.train.Saver()  \n",
    "with tf.Session() as sess:  \n",
    "    sess.run(init)  \n",
    "    save_path = saver.save(sess,\"./save_par/save_par.ckpt\")  \n",
    "    print (\"save to path:\",save_path)  \n",
    "    print (\"weights:\",sess.run(W))  \n",
    "    print (\"biases:\",sess.run(b)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"10\">10、加载数据</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "#W = tf.Variable(np.arange(6).reshape((2,3)),dtype = tf.float32,name='weight')  \n",
    "#b = tf.Variable(np.arange(3).reshape((1,3)),dtype = tf.float32,name='biases')  \n",
    "  \n",
    "#saver = tf.train.Saver()  \n",
    "#with tf.Session() as sess:  \n",
    "#        saver.restore(sess,\"./save_par/save_par.ckpt\")  \n",
    "#        print (\"weights:\",sess.run(W))  \n",
    "#        print (\"biases:\",sess.run(b))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"11\">11、变量的赋值不要用run</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "通过sess.run的方式读变量所需的时间: 0.924973011017\n",
      "通过直接赋值的手段读变量所需的时间: 0.000540018081665\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "t1 = time.time()  \n",
    "x = tf.Variable([1.0])  \n",
    "b =1.0  \n",
    "start1 = time.time()  \n",
    "with tf.Session() as sess:  \n",
    "    sess.run(tf.global_variables_initializer())  \n",
    "    #通过sess.run的方式读变量  \n",
    "    for step in range(5000):  \n",
    "        res = sess.run(x)  \n",
    "    print(\"通过sess.run的方式读变量所需的时间:\",time.time()-start1)  \n",
    "    start2 = time.time()  \n",
    "    for step in range(5000):  \n",
    "        a = b  \n",
    "    print(\"通过直接赋值的手段读变量所需的时间:\",time.time()-start2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"12\">12、print输出到文件</span>\n",
    "这个功能不是TensorFlow的，放在这里只是它也很常用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello weird\n",
      "Hello weird\n",
      "Hello weird\n",
      "Hello weird\n",
      "Hello weird\n",
      "Hello weird\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f=open('a.txt','a+') # 追加\n",
    "\n",
    "old=sys.stdout #将当前系统输出储存到一个临时变量中\n",
    "sys.stdout=f  #输出重定向到文件\n",
    "print('Hello weird') #测试一个打印输出\n",
    "sys.stdout.flush() # 刷新文件流\n",
    "sys.stdout=old #还原原系统输出\n",
    "f.close() \n",
    "print(open('a.txt','r').read())\n",
    "\n",
    "# 第二种方法\n",
    "# f=open('test.txt','a+')\n",
    "# s= '123'\n",
    "# abc= '456'\n",
    "# print >> f, s,abc\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"13\">13、使用初始化函数</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting shape:\n",
      "[[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]]\n"
     ]
    }
   ],
   "source": [
    "value = [0,1,2,3,4,5,6,7]\n",
    "#value = np.array(value)  # 注释掉没有影响\n",
    "#value = value.reshape([2,4])\n",
    "init = tf.constant_initializer(value)\n",
    "print('fitting shape:')\n",
    "tf.reset_default_graph()\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[2,4],initializer=init)  # 这个例子不实用，因为是确定的数值，不是随机数，完全可以用是Variable代替\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "larger shape:\n",
      "[[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]\n",
      " [ 7.  7.  7.  7.]]\n"
     ]
    }
   ],
   "source": [
    "print('larger shape:')  #小型的初始化是不允许的，也就是说shape小于原来的大小\n",
    "tf.reset_default_graph()\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[3,4],initializer = init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_normal_initializer:\n",
      "[[ 0.32421499 -1.00479341  0.26118875 -2.25137758]\n",
      " [-0.84631264 -0.2015401  -0.5502848  -0.18265748]\n",
      " [-0.14240623  1.87447703 -0.38946101 -0.75325561]]\n"
     ]
    }
   ],
   "source": [
    "print('random_normal_initializer:')\n",
    "tf.reset_default_graph()\n",
    "init = tf.random_normal_initializer(mean=0.0,stddev=1.0) #正态分布函数\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[3,4],initializer = init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truncated_normal_initializer:\n",
      "[[ 0.45091966  0.54714847 -0.44627866  1.99480319]\n",
      " [ 0.59979331 -0.79542363 -0.9042269   0.40124264]\n",
      " [-0.20564921 -0.25250092  0.71303296 -0.73212081]]\n"
     ]
    }
   ],
   "source": [
    "print('truncated_normal_initializer:')    # 截断正态分布\n",
    "tf.reset_default_graph()\n",
    "init = tf.truncated_normal_initializer(mean=0.0,stddev=1.0)\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[3,4],initializer = init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_uniform_initializer:\n",
      "[[ 0.79297531  0.25500691  0.3216548   0.62649357]\n",
      " [ 0.5831902   0.22098529  0.34389579  0.14673936]\n",
      " [ 0.49860525  0.50720167  0.89963949  0.09365726]]\n"
     ]
    }
   ],
   "source": [
    "print('random_uniform_initializer:')\n",
    "tf.reset_default_graph()\n",
    "init = tf.random_uniform_initializer(minval=0,maxval=None) #均匀分布随机数\n",
    "with tf.Session():\n",
    "  x = tf.get_variable('x',shape=[3,4],initializer = init)\n",
    "  x.initializer.run()\n",
    "  print(x.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "【说明】：\n",
    "tf.random_normal | tf.truncated_normal | tf.random_uniform\n",
    "tf.random_normal(shape,mean=0.0,stddev=1.0,dtype=tf.float32,seed=None,name=None)\n",
    "tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "tf.random_uniform(shape,minval=0,maxval=None,dtype=tf.float32,seed=None,name=None)\n",
    "这几个都是用于生成随机数tensor的。尺寸是shape\n",
    "random_normal: 正太分布随机数，均值mean,标准差stddev\n",
    "truncated_normal:截断正态分布随机数，均值mean,标准差stddev,不过只保留[mean-2*stddev,mean+2*stddev]范围内的随机数\n",
    "random_uniform:均匀分布随机数，范围为[minval,maxval]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"14\">14、命名域与共享变量</span>\n",
    "实际上，tf.name_scope与tf.variable_scope都可以用来声明命名域，但一般\n",
    "```\n",
    "tf.name_scope与tf.Variable一同使用\n",
    "tf.variable_scope与tf.variable_scope一同使用\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo/bar/v:0\n",
      "foo/bar/v:0\n",
      "foo1/bar1/v:0\n",
      "foo1/bar1/v:0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "# 不同的命名域与变量\n",
    "with tf.variable_scope(\"foo\"):\n",
    "  with tf.variable_scope(\"bar\"):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    print(v.name)\n",
    "\n",
    "print(v.name)\n",
    "\n",
    "with tf.variable_scope(\"foo1\"):\n",
    "  with tf.variable_scope(\"bar1\"):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    print(v.name)\n",
    "print(v.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'xxx/a:0' shape=(1,) dtype=float32_ref> <tf.Variable 'xxx/a:0' shape=(1,) dtype=float32_ref>\n",
      "[-0.67850912] [-0.67850912]\n"
     ]
    }
   ],
   "source": [
    "# 变量共享（相同变量）\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "with tf.variable_scope(\"xxx\"):\n",
    "  a = tf.get_variable(\"a\",[1])\n",
    "with tf.variable_scope(\"xxx\",reuse=True):   # 采用xxx/a的值\n",
    "  a1 = tf.get_variable(\"a\",[1])\n",
    "print(a,a1)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(a.eval(),a1.eval()) #如果初始化为None,则会采用variable_scope的初始化值，\n",
    "# 如果也是None,则采用uniform_unit_scaling_initializer\n",
    "assert a==a1  # a , a1 是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 变量共享（相同变量）另一种写法\n",
    "tf.reset_default_graph()\n",
    "with tf.variable_scope(\"yyy\") as scope:\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    scope.reuse_variables()\n",
    "    v1 = tf.get_variable(\"v\", [1])\n",
    "assert v1 == v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 为防止在没有使用reuse的情况下出现相现的共享变量，则会弹出异常,如下面是有错误的\n",
    "# with tf.variable_scope(\"zzz\"):\n",
    "  # v = tf.get_variable(\"v\",[1])\n",
    "  # v1 = tf.get_variable(\"v\",[1])\n",
    "  # Raises ValueError(\"...v already exists ...\").\n",
    "  \n",
    "# 为防止在使用reuse的情况下引用了之前没有的共享变量，则会弹出异常，如下面是有错误的\n",
    "# with tf.variable_scope(\"aaa\",reuse=True):\n",
    "  # v = tf.get_variable(\"v\",[1])\n",
    "  # Raises ValueError(\"... v does not exists...\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"15\">15.查看CPU与GPU使用</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CPU:\n",
    "    sensors   or   watch sensors\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "GPU:\n",
    "    nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader\n",
    "    or \n",
    "    nvidia-smi -a  # 可以看到显示的所有信息，包括什么温度会关自动关闭\n",
    "    or\n",
    "    watch -n 1 nvidia-smi  # 1秒的频率\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"16\">16.tf.reshape</span>\n",
    "```\n",
    "tf.reshape(tensor,shape,name=None)\n",
    "\n",
    "顾名思义，就是将tensor按照新的shape重新排列。一般来说，shape有三种用法： \n",
    "如果 shape=[-1], 表示要将tensor展开成一个list \n",
    "如果 shape=[a,b,c,…] 其中每个a,b,c,..均>0，那么就是常规用法 \n",
    "如果 shape=[a,-1,c,…] 此时b=-1，a,c,..依然>0。这表示tf会根据tensor的原尺寸，自动计算b的值。 \n",
    "官方给的例子已经很详细了，我就不写示例代码了\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# 官方例子\n",
    "# tensor 't' is [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "# tensor 't' has shape [9]\n",
    "reshape(t, [3, 3]) ==> [[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]]\n",
    "\n",
    "# tensor 't' is [[[1, 1], [2, 2]],\n",
    "#                [[3, 3], [4, 4]]]\n",
    "# tensor 't' has shape [2, 2, 2]\n",
    "reshape(t, [2, 4]) ==> [[1, 1, 2, 2],\n",
    "                        [3, 3, 4, 4]]\n",
    "\n",
    "# tensor 't' is [[[1, 1, 1],\n",
    "#                 [2, 2, 2]],\n",
    "#                [[3, 3, 3],\n",
    "#                 [4, 4, 4]],\n",
    "#                [[5, 5, 5],\n",
    "#                 [6, 6, 6]]]\n",
    "# tensor 't' has shape [3, 2, 3]\n",
    "# pass '[-1]' to flatten 't'\n",
    "reshape(t, [-1]) ==> [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]\n",
    "\n",
    "# -1 can also be used to infer the shape\n",
    "# -1 is inferred to be 9:\n",
    "reshape(t, [2, -1]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]\n",
    "\n",
    "# -1 is inferred to be 2:\n",
    "reshape(t, [-1, 9]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]\n",
    "\n",
    "# -1 is inferred to be 3:\n",
    "reshape(t, [ 2, -1, 3]) ==> [[[1, 1, 1],\n",
    "                              [2, 2, 2],\n",
    "                              [3, 3, 3]],\n",
    "                             [[4, 4, 4],\n",
    "                              [5, 5, 5],\n",
    "                              [6, 6, 6]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"17\">17.tf.transpose</span>\n",
    "转置函数：\n",
    "\n",
    "转见：[csdn](http://blog.csdn.net/u010417185/article/details/51900441)\n",
    "\n",
    "### <span id = \"18\">18.tf.gather</span>\n",
    "筛选函数：\n",
    "\n",
    "转见：[csdn](http://blog.csdn.net/guotong1988/article/details/53172882)\n",
    "\n",
    "### <span id = \"19\">19.加减乘除</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtracting a from b: 1.0\n",
      "Adding a and b: 12.0\n",
      "Multiplying a and b: 35.75\n",
      "Dividing a and b: 1.18182\n",
      "Floor dividing a and b: 1.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.constant(5.5)\n",
    "b = tf.constant(6.5)\n",
    "sess = tf.InteractiveSession()\n",
    "print(\"Subtracting a from b:\",sess.run(tf.subtract(b, a)))\n",
    "print(\"Adding a and b:\",sess.run(tf.add(a, b)))\n",
    "print(\"Multiplying a and b:\",sess.run(tf.multiply(a, b)))\n",
    "print(\"Dividing a and b:\",sess.run(tf.divide(b, a)))\n",
    "print(\"Floor dividing a and b:\",sess.run(tf.floor_div(b, a)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
